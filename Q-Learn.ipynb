{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random, math, gym\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython import display\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------- BRAIN ---------------------------\n",
    "\n",
    "class Brain:\n",
    "    def __init__(self, stateCnt, actionCnt):\n",
    "        self.stateCnt = stateCnt\n",
    "        self.actionCnt = actionCnt\n",
    "\n",
    "        self.model = self._createModel()\n",
    "        #self.model.load_weights(\"brain.h5\")\n",
    "\n",
    "    def _createModel(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(output_dim=128, activation='relu', input_dim=stateCnt))\n",
    "        model.add(Dense(output_dim=128, activation='relu'))\n",
    "        model.add(Dense(output_dim=actionCnt, activation='linear'))\n",
    "\n",
    "        opt = RMSprop(lr=0.00025)\n",
    "        model.compile(loss='mse', optimizer=opt)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self, x, y, epoch=1, verbose=0):\n",
    "        self.model.fit(x, y, batch_size=64, nb_epoch=epoch, verbose=verbose)\n",
    "\n",
    "    def predict(self, s):\n",
    "        return self.model.predict(s)\n",
    "\n",
    "    def predictOne(self, s):\n",
    "        return self.predict(s.reshape(1, self.stateCnt)).flatten()\n",
    "\n",
    "#-------------------- MEMORY --------------------------\n",
    "class Memory:   # stored as ( s, a, r, s_ )\n",
    "    samples = []\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "\n",
    "    def add(self, sample):\n",
    "        self.samples.append(sample)        \n",
    "\n",
    "        if len(self.samples) > self.capacity:\n",
    "            self.samples.pop(0)\n",
    "\n",
    "    def sample(self, n):\n",
    "        n = min(n, len(self.samples))\n",
    "        return random.sample(self.samples, n)\n",
    "\n",
    "#-------------------- AGENT ---------------------------\n",
    "MEMORY_CAPACITY = 100000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "GAMMA = 0.99\n",
    "\n",
    "MAX_EPSILON = 1\n",
    "MIN_EPSILON = 0.01\n",
    "LAMBDA = 0.001      # speed of decay\n",
    "\n",
    "class Agent:\n",
    "    steps = 0\n",
    "    epsilon = MAX_EPSILON\n",
    "\n",
    "    def __init__(self, stateCnt, actionCnt):\n",
    "        self.stateCnt = stateCnt\n",
    "        self.actionCnt = actionCnt\n",
    "\n",
    "        self.brain = Brain(stateCnt, actionCnt)\n",
    "        self.memory = Memory(MEMORY_CAPACITY)\n",
    "        \n",
    "    def act(self, s):\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.randint(0, self.actionCnt-1)\n",
    "        else:\n",
    "            return np.argmax(self.brain.predictOne(s))\n",
    "\n",
    "    def observe(self, sample):  # in (s, a, r, s_) format\n",
    "        self.memory.add(sample)        \n",
    "\n",
    "        # slowly decrease Epsilon based on our eperience\n",
    "        self.steps += 1\n",
    "        self.epsilon = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * math.exp(-LAMBDA * self.steps)\n",
    "\n",
    "    def replay(self):    \n",
    "        batch = self.memory.sample(BATCH_SIZE)\n",
    "        batchLen = len(batch)\n",
    "\n",
    "        no_state = np.zeros(self.stateCnt)\n",
    "\n",
    "        states = np.array([ o[0] for o in batch ])\n",
    "        states_ = np.array([ (no_state if o[3] is None else o[3]) for o in batch ])\n",
    "\n",
    "        p = self.brain.predict(states)\n",
    "        p_ = self.brain.predict(states_)\n",
    "\n",
    "        x = np.zeros((batchLen, self.stateCnt))\n",
    "        y = np.zeros((batchLen, self.actionCnt))\n",
    "        \n",
    "        for i in range(batchLen):\n",
    "            o = batch[i]\n",
    "            s = o[0]; a = o[1]; r = o[2]; s_ = o[3]\n",
    "            \n",
    "            t = p[i]\n",
    "            if s_ is None:\n",
    "                t[a] = r\n",
    "            else:\n",
    "                t[a] = r + GAMMA * np.amax(p_[i])\n",
    "\n",
    "            x[i] = s\n",
    "            y[i] = t\n",
    "\n",
    "        self.brain.train(x, y)\n",
    "\n",
    "#-------------------- ENVIRONMENT ---------------------\n",
    "class GymEnvironment:\n",
    "    def __init__(self, problem):\n",
    "        self.problem = problem\n",
    "        self.env = gym.make(problem)\n",
    "\n",
    "    def run(self, agent):\n",
    "        s = self.env.reset()\n",
    "        R = 0 \n",
    "\n",
    "        while True:            \n",
    "            self.env.render()\n",
    "\n",
    "            a = agent.act(s)\n",
    "\n",
    "            s_, r, done, info = self.env.step(a)\n",
    "\n",
    "            if done: # terminal state\n",
    "                s_ = None\n",
    "\n",
    "            agent.observe( (s, a, r, s_) )\n",
    "            agent.replay()            \n",
    "\n",
    "            s = s_\n",
    "            R += r\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        print(\"Total reward:\", R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self, grid_size):\n",
    "        self.grid_size = grid_size\n",
    "        \n",
    "    def run(self, agent):\n",
    "        self.reset()\n",
    "        s = self.state\n",
    "        R = 0 \n",
    "\n",
    "        while True:            \n",
    "            a = agent.act(s)\n",
    "\n",
    "            s_, r, done = self.act(a)\n",
    "\n",
    "            if done: # terminal state\n",
    "                s_ = None\n",
    "\n",
    "            agent.observe( (s, a, r, s_) )\n",
    "            agent.replay()            \n",
    "\n",
    "            s = s_\n",
    "            R += r\n",
    "            \n",
    "            self.render()\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        print(\"Total reward:\", R)\n",
    "\n",
    "    def _update_state(self, action):\n",
    "        \"\"\"\n",
    "        Input: action and states\n",
    "        Ouput: new states and reward\n",
    "        \"\"\"\n",
    "        state = self.state\n",
    "        # 0 = left\n",
    "        # 1 = right\n",
    "        # 2 = down\n",
    "        # 3 = up\n",
    "        \n",
    "        fy, fx, py, px, t, d = state\n",
    "        \n",
    "        old_d = abs(fx - px) + abs(fy - py)\n",
    "        \n",
    "        if action == 0:\n",
    "            if px > 0:\n",
    "                px -= 1\n",
    "        if action == 1:\n",
    "            if px < self.grid_size-1:\n",
    "                px += 1\n",
    "        if action == 2:\n",
    "            if py > 0:\n",
    "                py-= 1\n",
    "        if action == 3:\n",
    "            if py < self.grid_size-1:\n",
    "                py += 1\n",
    "                \n",
    "        new_d = abs(fx - px) + abs(fy - py)\n",
    "        \n",
    "        out = np.array([fy, fx, py, px, t-1, old_d-new_d])\n",
    "        self.state = out\n",
    "\n",
    "    def _draw_state(self):\n",
    "        im_size = (self.grid_size,)*2\n",
    "        state = self.state\n",
    "        if state[0] == state[2] and state[1] == state[3]:\n",
    "            canvas = np.ones(im_size)\n",
    "        else:\n",
    "            canvas = np.zeros(im_size)\n",
    "        canvas[state[0], state[1]] = 1  # draw fruit\n",
    "        canvas[state[2], state[3]] = 0.5  # draw basket\n",
    "        self.canvas = canvas\n",
    "        return canvas\n",
    "\n",
    "    def _get_reward(self):\n",
    "        fruit_y, fruit_x, player_y, player_x, t, d = self.state\n",
    "        \n",
    "        if fruit_x == player_x and fruit_y == player_y:\n",
    "            return 1\n",
    "        \n",
    "        if d == 1:\n",
    "            return 0.1\n",
    "        \n",
    "        if d == 0:\n",
    "            return -0.1\n",
    "        \n",
    "        if d == -1:\n",
    "            return -1\n",
    "\n",
    "\n",
    "    def _is_over(self):\n",
    "        fruit_y, fruit_x, player_y, player_x, t, d = self.state\n",
    "        \n",
    "        if t == 0:\n",
    "            return True\n",
    "        \n",
    "        if fruit_x == player_x and fruit_y == player_y:\n",
    "            return True\n",
    "    \n",
    "        return False\n",
    "\n",
    "    def observe(self):\n",
    "        canvas = self._draw_state()\n",
    "        return canvas.reshape((1, -1))\n",
    "    \n",
    "    def render(self):\n",
    "        self._draw_state()\n",
    "        plt.gca().cla()\n",
    "        plt.imshow(self.canvas)\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "\n",
    "    def act(self, action):\n",
    "        self._update_state(action)\n",
    "        reward = self._get_reward()\n",
    "        game_over = self._is_over()\n",
    "        return self.state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        fruit_x = np.random.randint(0, self.grid_size-1)\n",
    "        fruit_y = np.random.randint(0, self.grid_size-1)\n",
    "        player_x = np.random.randint(0, self.grid_size-1)\n",
    "        player_y = np.random.randint(0, self.grid_size-1)\n",
    "        time = abs(fruit_x - player_x) + abs(fruit_y - player_y)\n",
    "        time *= 2\n",
    "        \n",
    "        while abs(fruit_x - player_x) + abs(fruit_y - player_y) < self.grid_size/2:\n",
    "            fruit_x = np.random.randint(0, self.grid_size-1)\n",
    "            fruit_y = np.random.randint(0, self.grid_size-1)\n",
    "            player_x = np.random.randint(0, self.grid_size-1)\n",
    "            player_y = np.random.randint(0, self.grid_size-1)\n",
    "            time = abs(fruit_x - player_x) + abs(fruit_y - player_y)\n",
    "            time *= 2\n",
    "            \n",
    "        self.state = np.asarray([fruit_y, fruit_x, player_y, player_x, time, 0])\n",
    "        self._draw_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff39dc8cb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-aabc93679dea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"brain.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-aa657bec4bec>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, agent)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mR\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-aa657bec4bec>\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mcla\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspine\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m             \u001b[0mspine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_existing_data_limits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/spines.py\u001b[0m in \u001b[0;36mcla\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# clear position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_frame_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mcla\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    771\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_artist_props\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mreset_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminorTicks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajorTicks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminorTicks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lastNumMajorTicks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick\u001b[0;34m(self, major)\u001b[0m\n\u001b[1;32m   2095\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2096\u001b[0m             \u001b[0mtick_kw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_minor_tick_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2097\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mYTick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmajor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtick_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, axes, loc, label, size, width, color, tickdir, pad, labelsize, labelcolor, zorder, gridOn, tick1On, tick2On, label1On, label2On, major, labelrotation)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[0;32m---> 68\u001b[0;31m     def __init__(self, axes, loc, label,\n\u001b[0m\u001b[1;32m     69\u001b[0m                  \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                  \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff39dc8cb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#-------------------- MAIN ----------------------------\n",
    "\n",
    "env = Environment(100)\n",
    "stateCnt = 6\n",
    "actionCnt = 4\n",
    "\n",
    "agent = Agent(stateCnt, actionCnt)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    env.run(agent)\n",
    "\n",
    "agent.brain.model.save(\"brain.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
